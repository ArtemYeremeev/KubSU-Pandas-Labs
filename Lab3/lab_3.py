# -*- coding: utf-8 -*-
"""Lab_3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BoxHl_u38HSzKpVucVF0GCLDHVDVU8US

**Работа №3. Еремеев А.С.**

Импорты
"""

from matplotlib.colors import ListedColormap
from sklearn import model_selection, datasets, linear_model, metrics

import numpy as np

# Commented out IPython magic to ensure Python compatibility.
# %pylab inline

"""**1. Сгенерируйте данные создав 4 признака (2 информативных)**

"""

data, target, coef = datasets.make_regression(n_features = 4, n_informative = 2, n_targets = 1, 
                                              noise = 5., coef = True, random_state = 2)

"""**2. Изобразите данные на плоскости (каждый признак с таргетом) используйте разные цвета**"""

pylab.scatter(data[:,0], target, color = 'red')
pylab.scatter(data[:,1], target, color = 'blue')
pylab.scatter(data[:,2], target, color = 'green')
pylab.scatter(data[:,3], target, color = 'purple')

"""**3. Разбейте данные на обучение и тест, отправим в тестовую выборку 25% всех данных**"""

train_data, test_data, train_labels, test_labels = model_selection.train_test_split(data, target,  
                                                                                     test_size = 0.25)

"""**4. Оцените линейную регрессионную модель, выведите ее уравнение**"""

linear_regressor = linear_model.LinearRegression() #создаем классификатор
linear_regressor.fit(train_data, train_labels)     #настраиваем его на обучающей выборке
predictions = linear_regressor.predict(test_data)  #используем его для предсказаний на тестовой выборке

print("Тестовые значения -", test_labels)
print("Предсказанные значения -", predictions)

print("y = {:.2f}*x1 + {:.2f}*x2 + {:.2f}*x3 + {:.2f}*x4".format(coef[0], coef[1], coef[2], coef[3])) #Уравнение без сводобного члена

print("y = {:.2f}*x1 + {:.2f}*x2 + {:.2f}*x3 + {:.2f}*x4 + {:.2f}".format(linear_regressor.coef_[0], 
                                                  linear_regressor.coef_[1],
                                                  linear_regressor.coef_[2],
                                                  linear_regressor.coef_[3],
                                                  linear_regressor.intercept_)) #Уравнение со свободным членом

"""**5. Оцените качество уравнения регрессии, вычислив MAE, MSE, R2 метрики**"""

print("Средняя абсолютная ошибка -", metrics.mean_absolute_error(test_labels, predictions)) #измеряем качество MAE
print("Среднеквадратичная ошибка -", metrics.mean_squared_error(test_labels, predictions)) #измеряем качество MSE
print("Коэффициент детерминации -", metrics.r2_score(test_labels, predictions)) #измеряем качество R2

"""**6. Проведите кросс-валидацию по 7 блокам, используя в качестве scoring среднеквадратичную ошибку.**"""

scorer = metrics.make_scorer(metrics.mean_squared_error, greater_is_better=True) #scorer по среднеквадратичной ошибке
linear_scoring = model_selection.cross_val_score(linear_regressor, data, target, scoring=scorer, 
                                                  cv = 7)

"""**7. Выведите результаты по кросс-валидации, рассчитайте максимальное, минимальное, среднее значения, а также среднеквадратичное отклонение**"""

print("Результат кроссвалидации -", linear_scoring)

print('Минимальное значение: {}'.format(linear_scoring.min()))
print('Среднее значение: {}'.format(linear_scoring.mean()))
print('Максимальное значение: {}'.format(linear_scoring.max()))
print('Среднеквадратичное отклонение: {}'.format(linear_scoring.std()))