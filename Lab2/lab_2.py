# -*- coding: utf-8 -*-
"""Lab_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SweeVizs08n4GSermc2hFo2Tur2bHWGC

**Работа №2. Еремеев А.С.**

Импорты
"""

from matplotlib.colors import ListedColormap
from sklearn import model_selection, datasets, linear_model, metrics
import numpy as np
import pandas as pd

# Commented out IPython magic to ensure Python compatibility.
# %pylab inline

"""Загрузка данных"""

data_url = 'https://raw.githubusercontent.com/ArtemYeremeev/KubSU-Pandas-Labs/main/Lab2/telecom_churn.csv'
df = pd.read_csv(data_url)
df.head(10)

"""**1. Сформируйте выборку X и ответы к ней y, выбрав в качестве признаков: "Customer service calls" и "Total day charge". В качестве результативного признака выберете "Churn", предварительно преобразовав его к числовому формату**"""

df['Churn'] = df['Churn'].astype(int)
data = df[['Customer service calls', 'Total day charge', 'Churn']].sample(n=200, random_state=1)
print(data)

"""**2. Изобразите выборку графически, отметив класс лояльных клиентов зеленым цветов, а не лояльных-красным**

Вариант 1
"""

data["Color"] = data.apply(lambda x: "green" if x["Churn"] == 0 else "red", axis=1)
groups = data.groupby('Churn')

# При запуске на белом фоне поменять параметр color на "black"
plt.title("Зависимость ухода абонента от количества звонков в поддержку и абонентской платы", color="white", fontsize=14)
plt.xlabel('Оплата в день', color="white", fontsize=14)
plt.ylabel('Количество звонков в справку', color="white", fontsize=14)

for n, group in groups:
  if group["Color"].any() == "red":
    color = "red"
  else:
    color = "green"
  plt.plot(group["Total day charge"], group["Customer service calls"], marker="o", linestyle="", label=n, color=color)

"""Вариант 2"""

data["Color"] = data.apply(lambda x: "green" if x["Churn"] == 0 else "red", axis=1)

# При запуске на белом фоне поменять параметр color на "black"
plt.title("Зависимость ухода абонента от количества звонков в поддержку и абонентской платы", color="white", fontsize=14)
plt.xlabel('Оплата в день', color="white", fontsize=14)
plt.ylabel('Количество звонков в справку', color="white", fontsize=14)

plt.scatter(data["Total day charge"], data["Customer service calls"], c=data["Color"])

"""*Анализ результата:* полученный график не отражает существующей зависимости между признаками "Total day charge", "Customer service calls" и "Churn", что допускает вероятность ее отсутствия.

**3. Разбейте выборку на обучение и тест, использовав метод train_test_split библиотеки model selection в пропорции 70-30, параметр random state = 1**
"""

data_df = data[["Total day charge", "Customer service calls"]].copy() #Отбираем анализируемые колонки
labels_df = data["Churn"].copy() #Отбираем результирующую колонку

data_list = data_df.to_numpy().tolist() #Приведение к списку списков
data_labels = labels_df.to_numpy().tolist() #Приведение к списку

train_data, test_data, train_labels, test_labels = model_selection.train_test_split(data_list, data_labels, 
                                                                                    test_size = 0.3,
                                                                                    random_state = 1)

"""**4. Создайте объект ridge classifier, настройте его на обучающей выборке и примените его к тестовым данным. Посмотрите на результат. Почему мы получили константную модель?**"""

ridge_classifier = linear_model.RidgeClassifier(random_state = 1)

ridge_classifier.fit(train_data, train_labels)

ridge_predictions = ridge_classifier.predict(test_data)
print(ridge_predictions)

"""*Анализ результата:* Полученная констатная модель, выдающая 0 значение при любой комбинации признаков "Total day charge" и "Customer service calls" свидетельствует об отсутствии зависимости между ними и результирующим признаком ухода пользователя от оператора ("Churn"), подтверждая выводы, полученные графически.

**5. Повторите п.4 для логистической регрессии, для тестовых данных рассчитайте вероятность отнесения объекта к каждому классу**
"""

log_regressor = linear_model.LogisticRegression(random_state = 1)

log_regressor.fit(train_data, train_labels)

lr_predictions = log_regressor.predict(test_data)

lr_proba_predictions = log_regressor.predict_proba(test_data)

print("Имеющиеся данные об уходе абонента -", test_labels)
print("Предсказанные логистической моделью результаты -", lr_predictions)

"""**6. Вычислите метрики качества для обеих моделей, а также confusion matrix**"""

#Качество
print(metrics.accuracy_score(test_labels, ridge_predictions))
print(metrics.accuracy_score(test_labels, lr_predictions))

#Точность
print(metrics.precision_score(test_labels, ridge_predictions))
print(metrics.precision_score(test_labels, lr_predictions))

#Полнота
print(metrics.recall_score(test_labels, ridge_predictions))
print(metrics.recall_score(test_labels, lr_predictions))

#Confusion matrix
print(metrics.confusion_matrix(test_labels, ridge_predictions))
print(metrics.confusion_matrix(test_labels, lr_predictions))

"""**7. Проведите процедуру крос-валидации для построенных моделей, вычислите среднее значение метрики accuracy для каждой из моделей**"""

ridge_scoring = model_selection.cross_val_score(ridge_classifier, data_list, data_labels, scoring = 'accuracy', cv = 10)
lr_scoring = model_selection.cross_val_score(log_regressor, data_list, data_labels, scoring = 'accuracy', cv = 10)

print(ridge_scoring)
print(lr_scoring)

print('Ridge mean:{}, max:{}, min:{}, std:{}'.format(ridge_scoring.mean(), ridge_scoring.max(), 
                                                     ridge_scoring.min(), ridge_scoring.std()))

print('Log mean:{}, max:{}, min:{}, std:{}'.format(lr_scoring.mean(), lr_scoring.max(), 
                                                   lr_scoring.min(), lr_scoring.std()))